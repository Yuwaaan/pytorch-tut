{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd4a89c-fb40-4017-b603-d441fecc4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24cf125-5308-43b2-a6af-0351813cccfa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Creating tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a7c74-4e65-49b7-866a-ba46ef81bf50",
   "metadata": {},
   "source": [
    "| Name | What is it? | Number of dimensions | Lower or upper (usually/example) |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| **scalar** | a single number | 0 | Lower (`a`) | \n",
    "| **vector** | a number with direction (e.g. wind speed with direction) but can also have many other numbers | 1 | Lower (`y`) |\n",
    "| **matrix** | a 2-dimensional array of numbers | 2 | Upper (`Q`) |\n",
    "| **tensor** | an n-dimensional array of numbers | can be any number, a 0-dimension tensor is a scalar, a 1-dimension tensor is a vector | Upper (`X`) | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f85f93d-2ff0-4c72-acdf-61ec6ed473f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Getting a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd478cb5-1706-4b14-8be4-723eac70f3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  4 19:41:52 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 536.45                 Driver Version: 536.45       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   57C    P8               1W /  55W |   4592MiB /  8188MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     30340      C   ...oftware\\Python\\Python310\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     36900      C   ...oftware\\Python\\Python310\\python.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "338bb6fd-6241-48bd-9811-d3cf9ecae8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2+cu121\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "# Set device type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "282486a5-9804-4e29-bcc2-66522c0f9e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], device='cuda:0') cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Putting tensors on the GPU\n",
    "tensor_on_gpu = torch.tensor([1, 2, 3]).to(device)\n",
    "print(tensor_on_gpu, tensor_on_gpu.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "568e387a-9e05-4718-bfa3-0c79c3ba9432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moving tensors back to the CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df650967-952b-4323-8514-95ff34feff3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## The PyTorch Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2723526-3e6c-45c3-9ac9-ae5a273d3335",
   "metadata": {},
   "source": [
    "| **Topic** | **Contents** |\n",
    "| ----- | ----- |\n",
    "| **1. Getting data ready** | Data can be almost anything but to get started we're going to create a simple straight line |\n",
    "| **2. Building a model** | Here we'll create a model to learn patterns in the data, we'll also choose a **loss function**, **optimizer** and build a **training loop**. | \n",
    "| **3. Fitting the model to data (training)** | We've got data and a model, now let's let the model (try to) find patterns in the (**training**) data. |\n",
    "| **4. Making predictions and evaluating a model (inference)** | Our model's found patterns in the data, let's compare its findings to the actual (**testing**) data. |\n",
    "| **5. Saving and loading a model** | You may want to use your model elsewhere, or come back to it later, here we'll cover that. |\n",
    "| **6. Putting it all together** | Let's take all of the above and combine it. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea2bbb9-aaaa-4ff5-bacd-d55fedba09a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38724f08-365d-4420-aa59-eb37c7206f05",
   "metadata": {},
   "source": [
    "| Split | Purpose | Amount of total data | How often is it used? |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| **Training set** | The model learns from this data (like the course materials you study during the semester). | ~60-80% | Always |\n",
    "| **Validation set** | The model gets tuned on this data (like the practice exam you take before the final exam). | ~10-20% | Often but not always |\n",
    "| **Testing set** | The model gets evaluated on this data to test what it has learned (like the final exam you take at the end of the semester). | ~10-20% | Always |\n",
    "\n",
    "For now, we'll just use a training and test set, this means we'll have a dataset for our model to learn on as well as be evaluated on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c77d8-4b7a-4d4a-ae80-398fb349ba4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## PyTorch model building essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7003a-77d9-4c30-b994-8fd48e7abaa5",
   "metadata": {},
   "source": [
    "| PyTorch module | What does it do? |\n",
    "| ----- | ----- |\n",
    "| [`torch.nn`](https://pytorch.org/docs/stable/nn.html) | Contains all of the building blocks for computational graphs (essentially a series of computations executed in a particular way). |\n",
    "| [`torch.nn.Parameter`](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter) | Stores tensors that can be used with `nn.Module`. If `requires_grad=True` gradients (used for updating model parameters via [**gradient descent**](https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html))  are calculated automatically, this is often referred to as \"autograd\".  | \n",
    "| [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) | The base class for all neural network modules, all the building blocks for neural networks are subclasses. If you're building a neural network in PyTorch, your models should subclass `nn.Module`. Requires a `forward()` method be implemented. | \n",
    "| [`torch.optim`](https://pytorch.org/docs/stable/optim.html) | Contains various optimization algorithms (these tell the model parameters stored in `nn.Parameter` how to best change to improve gradient descent and in turn reduce the loss). | \n",
    "| `def forward()` | All `nn.Module` subclasses require a `forward()` method, this defines the computation that will take place on the data passed to the particular `nn.Module` (e.g. the linear regression formula above). |\n",
    "\n",
    "If the above sounds complex, think of like this, almost everything in a PyTorch neural network comes from `torch.nn`,\n",
    "* `nn.Module` contains the larger building blocks (layers)\n",
    "* `nn.Parameter` contains the smaller parameters like weights and biases (put these together to make `nn.Module`(s))\n",
    "* `forward()` tells the larger blocks how to make calculations on inputs (tensors full of data) within  `nn.Module`(s)\n",
    "* `torch.optim` contains optimization methods on how to improve the parameters within `nn.Parameter` to better represent input data\n",
    "\n",
    "![a pytorch linear model with annotations](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-pytorch-linear-model-annotated.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060a0567-d6ea-4fda-ad8e-7d5b458516c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Checking the contents of a PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5ca84-f6f9-4157-82fe-de17e5e68709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set manual seed since nn.Parameter are randomly initialzied\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create an instance of the model (this is a subclass of nn.Module that contains nn.Parameter(s))\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# Check the nn.Parameter(s) within the nn.Module subclass we created\n",
    "list(model_0.parameters())\n",
    "\n",
    "# List named parameters \n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0ca8fd-45e8-42e8-b812-0d8cbe1e47f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Creating a loss function and optimizer in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af499014-7d83-403d-8464-03d60ec86293",
   "metadata": {},
   "source": [
    "We've setup a loss (also called a criterion or cost function) and optimizer before in [notebook 01](https://www.learnpytorch.io/01_pytorch_workflow/#creating-a-loss-function-and-optimizer-in-pytorch).\n",
    "\n",
    "But different problem types require different loss functions. \n",
    "\n",
    "For example, for a regression problem (predicting a number) you might used mean absolute error (MAE) loss.\n",
    "\n",
    "And for a binary classification problem (like ours), you'll often use [binary cross entropy](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a) as the loss function.\n",
    "\n",
    "However, the same optimizer function can often be used across different problem spaces.\n",
    "\n",
    "For example, the stochastic gradient descent optimizer (SGD, `torch.optim.SGD()`) can be used for a range of problems, and the same applies to the Adam optimizer (`torch.optim.Adam()`). \n",
    "\n",
    "| Loss function/Optimizer | Problem type | PyTorch Code |\n",
    "| ----- | ----- | ----- |\n",
    "| Stochastic Gradient Descent (SGD) optimizer | Classification, regression, many others. | [`torch.optim.SGD()`](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html) |\n",
    "| Adam Optimizer | Classification, regression, many others. | [`torch.optim.Adam()`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) |\n",
    "| Binary cross entropy loss | Binary classification | [`torch.nn.BCELossWithLogits`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html) or [`torch.nn.BCELoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html) |\n",
    "| Cross entropy loss | Mutli-class classification | [`torch.nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) |\n",
    "| Mean absolute error (MAE) or L1 Loss | Regression | [`torch.nn.L1Loss`](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html) | \n",
    "| Mean squared error (MSE) or L2 Loss | Regression | [`torch.nn.MSELoss`](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss) |  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a6b0da-c76d-4f0d-8830-40b9434cf8e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## PyTorch training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44a576a-bd7b-4ecf-bf4e-fc4a0971b7ea",
   "metadata": {},
   "source": [
    "For the training loop, we'll build the following steps:\n",
    "\n",
    "| Number | Step name | What does it do? | Code example |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| 1 | Forward pass | The model goes through all of the training data once, performing its `forward()` function calculations. | `model(x_train)` |\n",
    "| 2 | Calculate the loss | The model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are. | `loss = loss_fn(y_pred, y_train)` | \n",
    "| 3 | Zero gradients | The optimizers gradients are set to zero (they are accumulated by default) so they can be recalculated for the specific training step. | `optimizer.zero_grad()` |\n",
    "| 4 | Perform backpropagation on the loss | Computes the gradient of the loss with respect for every model parameter to be updated  (each parameter with `requires_grad=True`). This is known as **backpropagation**, hence \"backwards\".  | `loss.backward()` |\n",
    "| 5 | Update the optimizer (**gradient descent**) | Update the parameters with `requires_grad=True` with respect to the loss gradients in order to improve them. | `optimizer.step()` |\n",
    "\n",
    "![pytorch training loop annotated](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-pytorch-training-loop-annotated.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0b1d2c-41f5-41df-b9d2-0d137a5234ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## PyTorch testing loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390a0a4-27c4-4417-8fad-9a6fb1a83257",
   "metadata": {},
   "source": [
    "As for the testing loop (evaluating our model), the typical steps include:\n",
    "\n",
    "| Number | Step name | What does it do? | Code example |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| 1 | Forward pass | The model goes through all of the training data once, performing its `forward()` function calculations. | `model(x_test)` |\n",
    "| 2 | Calculate the loss | The model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are. | `loss = loss_fn(y_pred, y_test)` | \n",
    "| 3 | Calulate evaluation metrics (optional) | Alongisde the loss value you may want to calculate other evaluation metrics such as accuracy on the test set. | Custom functions |\n",
    "\n",
    "Notice the testing loop doesn't contain performing backpropagation (`loss.backward()`) or stepping the optimizer (`optimizer.step()`), this is because no parameters in the model are being changed during testing, they've already been calculated. For testing, we're only interested in the output of the forward pass through the model.\n",
    "\n",
    "![pytorch annotated testing loop](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-pytorch-testing-loop-annotated.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870c6a2-fed6-4d39-a6d9-5def9e27251b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Improving a model (from a model perspective)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819b4d3-3e03-4bd8-892e-4a9a231d5702",
   "metadata": {},
   "source": [
    "Focusing specifically on the model (not the data), there are a few ways we could do this.\n",
    "\n",
    "| Model improvement technique* | What does it do? |\n",
    "| ----- | ----- |\n",
    "| **Add more layers** | Each layer *potentially* increases the learning capabilities of the model with each layer being able to learn some kind of new pattern in the data, more layers is often referred to as making your neural network *deeper*. |\n",
    "| **Add more hidden units** | Similar to the above, more hidden units per layer means a *potential* increase in learning capabilities of the model, more hidden units is often referred to as making your neural network *wider*. |\n",
    "| **Fitting for longer (more epochs)** | Your model might learn more if it had more opportunities to look at the data. |\n",
    "| **Changing the activation functions** | Some data just can't be fit with only straight lines (like what we've seen), using non-linear activation functions can help with this (hint, hint). |\n",
    "| **Change the learning rate** | Less model specific, but still related, the learning rate of the optimizer decides how much a model should change its parameters each step, too much and the model overcorrects, too little and it doesn't learn enough. |\n",
    "| **Change the loss function** | Again, less model specific but still important, different problems require different loss functions. For example, a binary cross entropy loss function won't work with a multi-class classification problem. |\n",
    "| **Use transfer learning** | Take a pretrained model from a problem domain similar to yours and adjust it to your own problem. We cover transfer learning in [notebook 06](https://www.learnpytorch.io/06_pytorch_transfer_learning/). |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e827c-ee46-4d7b-94cf-b640da85599d",
   "metadata": {},
   "source": [
    "## More classification evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413a7980-498f-46ff-a1e0-ffdd1372bf15",
   "metadata": {},
   "source": [
    "| **Metric name/Evaluation method** | **Defintion** | **Code** |\n",
    "| --- | --- | --- |\n",
    "| Accuracy | Out of 100 predictions, how many does your model get correct? E.g. 95% accuracy means it gets 95/100 predictions correct. | [`torchmetrics.Accuracy()`](https://torchmetrics.readthedocs.io/en/stable/classification/accuracy.html#id3) or [`sklearn.metrics.accuracy_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) |\n",
    "| Precision | Proportion of true positives over total number of samples. Higher precision leads to less false positives (model predicts 1 when it should've been 0). | [`torchmetrics.Precision()`](https://torchmetrics.readthedocs.io/en/stable/classification/precision.html#id4) or [`sklearn.metrics.precision_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html) |\n",
    "| Recall | Proportion of true positives over total number of true positives and false negatives (model predicts 0 when it should've been 1). Higher recall leads to less false negatives. | [`torchmetrics.Recall()`](https://torchmetrics.readthedocs.io/en/stable/classification/recall.html#id5) or [`sklearn.metrics.recall_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) |\n",
    "| F1-score | Combines precision and recall into one metric. 1 is best, 0 is worst. | [`torchmetrics.F1Score()`](https://torchmetrics.readthedocs.io/en/stable/classification/f1_score.html#f1score) or [`sklearn.metrics.f1_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) |\n",
    "| [Confusion matrix](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)  | Compares the predicted values with the true values in a tabular way, if 100% correct, all values in the matrix will be top left to bottom right (diagnol line). | [`torchmetrics.ConfusionMatrix`](https://torchmetrics.readthedocs.io/en/stable/classification/confusion_matrix.html#confusionmatrix) or [`sklearn.metrics.plot_confusion_matrix()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_predictions) |\n",
    "| Classification report | Collection of some of the main classification metrics such as precision, recall and f1-score. | [`sklearn.metrics.classification_report()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46445d00-adc8-4258-afd0-6d8b87c6cdfa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## How to deal with overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d42ddfa-1a4c-420f-8081-c87ba8922795",
   "metadata": {},
   "source": [
    "| **Method to prevent overfitting** | **What is it?** |\n",
    "| ----- | ----- |\n",
    "| **Get more data** | Having more data gives the model more opportunities to learn patterns, patterns which may be more generalizable to new examples. | \n",
    "| **Simplify your model** | If the current model is already overfitting the training data, it may be too complicated of a model. This means it's learning the patterns of the data too well and isn't able to generalize well to unseen data. One way to simplify a model is to reduce the number of layers it uses or to reduce the number of hidden units in each layer. | \n",
    "| **Use data augmentation** | [**Data augmentation**](https://developers.google.com/machine-learning/glossary#data-augmentation) manipulates the training data in a way so that's harder for the model to learn as it artificially adds more variety to the data. If a model is able to learn patterns in augmented data, the model may be able to generalize better to unseen data. |\n",
    "| **Use transfer learning** | [**Transfer learning**](https://developers.google.com/machine-learning/glossary#transfer-learning) involves leveraging the patterns (also called pretrained weights) one model has learned to use as the foundation for your own task. In our case, we could use one computer vision model pretrained on a large variety of images and then tweak it slightly to be more specialized for food images. |\n",
    "| **Use dropout layers** | Dropout layers randomly remove connections between hidden layers in neural networks, effectively simplifying a model but also making the remaining connections better. See [`torch.nn.Dropout()`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) for more. | \n",
    "| **Use learning rate decay** | The idea here is to slowly decrease the learning rate as a model trains. This is akin to reaching for a coin at the back of a couch. The closer you get, the smaller your steps. The same with the learning rate, the closer you get to [**convergence**](https://developers.google.com/machine-learning/glossary#convergence), the smaller you'll want your weight updates to be.  |\n",
    "| **Use early stopping** | [**Early stopping**](https://developers.google.com/machine-learning/glossary#early_stopping) stops model training *before* it begins to overfit. As in, say the model's loss has stopped decreasing for the past 10 epochs (this number is arbitrary), you may want to stop the model training here and go with the model weights that had the lowest loss (10 epochs prior). |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73654c-e418-41a1-b43f-555b1606225e",
   "metadata": {},
   "source": [
    "## How to deal with underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d9ccc8-643f-4093-9cd0-efa85a580153",
   "metadata": {},
   "source": [
    "| **Method to prevent underfitting** | **What is it?** |\n",
    "| ----- | ----- |\n",
    "| **Add more layers/units to your model** | If your model is underfitting, it may not have enough capability to *learn* the required patterns/weights/representations of the data to be predictive. One way to add more predictive power to your model is to increase the number of hidden layers/units within those layers. | \n",
    "| **Tweak the learning rate** | Perhaps your model's learning rate is too high to begin with. And it's trying to update its weights each epoch too much, in turn not learning anything. In this case, you might lower the learning rate and see what happens. |\n",
    "| **Use transfer learning** | Transfer learning is capable of preventing overfitting and underfitting. It involves using the patterns from a previously working model and adjusting them to your own problem. |\n",
    "| **Train for longer** | Sometimes a model just needs more time to learn representations of data. If you find in your smaller experiments your model isn't learning anything, perhaps leaving it train for a more epochs may result in better performance. |\n",
    "| **Use less regularization** | Perhaps your model is underfitting because you're trying to prevent overfitting too much. Holding back on regularization techniques can help your model fit the data better. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8655ca75-af24-4652-ad4e-ba6ed239a70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6b2598-72cc-4f23-a785-d2d8e2c99411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9208ef40-5eb5-4dc2-8009-0d7d2bc12f5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a832fb6-d5b9-4f48-84ea-2880ef48151c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 1]) torch.Size([40, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1676aa3a9e0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = torch.arange(0, 1, 0.02).unsqueeze(dim=1)\n",
    "y = 0.7 * X + 0.3\n",
    "\n",
    "# Create train/test split\n",
    "train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing \n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", s=4, label=\"Training data\")\n",
    "\n",
    "# Plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "# Show the legend\n",
    "plt.legend(prop={\"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e55be-b880-4b9b-ae8e-1610acb24dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
